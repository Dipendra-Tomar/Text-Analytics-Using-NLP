{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neurosensum_Translator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw2sjpaoKQEW",
        "colab_type": "text"
      },
      "source": [
        "# Let's try to create a Indonesian-English Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCRwrE0JKpl0",
        "colab_type": "text"
      },
      "source": [
        "## Loading libraries and datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jq55Q7sW8H7",
        "colab_type": "code",
        "outputId": "56c0305e-9f3e-4582-cd4d-6dba35058f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD239SrUX1Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_raw = pd.read_csv('assignment.csv', low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip37juJiYb5N",
        "colab_type": "code",
        "outputId": "965c6d12-dea4-4627-e52b-aab57d87c63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "data_raw.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!</td>\n",
              "      <td>Menginspirasi secara spiritual dan mental! Buku yang memungkinkan Anda mempertanyakan moral Anda dan akan membantu Anda menemukan siapa diri Anda sebenarnya!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This is one my must have books</td>\n",
              "      <td>Ini adalah salah satu yang harus saya miliki buku</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   unique_id  ...                                                                                                                                                    review_text\n",
              "0          0  ...  Menginspirasi secara spiritual dan mental! Buku yang memungkinkan Anda mempertanyakan moral Anda dan akan membantu Anda menemukan siapa diri Anda sebenarnya!\n",
              "1          1  ...                                                                                                              Ini adalah salah satu yang harus saya miliki buku\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcySw7jVYe8c",
        "colab_type": "code",
        "outputId": "a3b7483e-8e9c-4679-d0dd-2e4044b86a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_raw)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyNk44ldQw_s",
        "colab_type": "text"
      },
      "source": [
        "## Text Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmptnz5KQ3nf",
        "colab_type": "text"
      },
      "source": [
        "### Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuBBMDV-ZHDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copying out raw data\n",
        "data = data_raw.copy()\n",
        "data['review_text'] = data['review_text'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8_M2MdlRHwV",
        "colab_type": "code",
        "outputId": "4e524149-0da3-41e8-d280-1ecd6479e752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Getting rid of punctuations\n",
        "data['raw_text'] = data['raw_text'].str.translate(str.maketrans('', '', string.punctuation))\n",
        "data['review_text'] = data['review_text'].str.translate(str.maketrans('', '', string.punctuation))\n",
        "data.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Spiritually and mentally inspiring A book that allows you to question your morals and will help you discover who you really are</td>\n",
              "      <td>Menginspirasi secara spiritual dan mental Buku yang memungkinkan Anda mempertanyakan moral Anda dan akan membantu Anda menemukan siapa diri Anda sebenarnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This is one my must have books</td>\n",
              "      <td>Ini adalah salah satu yang harus saya miliki buku</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   unique_id  ...                                                                                                                                                  review_text\n",
              "0          0  ...  Menginspirasi secara spiritual dan mental Buku yang memungkinkan Anda mempertanyakan moral Anda dan akan membantu Anda menemukan siapa diri Anda sebenarnya\n",
              "1          1  ...                                                                                                            Ini adalah salah satu yang harus saya miliki buku\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je8eH-gESsCd",
        "colab_type": "code",
        "outputId": "f0a454e4-f9ff-47a8-b1b3-470e8c378faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# convert text to lower case\n",
        "data['raw_text'] = data['raw_text'].str.lower()\n",
        "data['review_text'] = data['review_text'].str.lower()\n",
        "data.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>spiritually and mentally inspiring a book that allows you to question your morals and will help you discover who you really are</td>\n",
              "      <td>menginspirasi secara spiritual dan mental buku yang memungkinkan anda mempertanyakan moral anda dan akan membantu anda menemukan siapa diri anda sebenarnya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>this is one my must have books</td>\n",
              "      <td>ini adalah salah satu yang harus saya miliki buku</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   unique_id  ...                                                                                                                                                  review_text\n",
              "0          0  ...  menginspirasi secara spiritual dan mental buku yang memungkinkan anda mempertanyakan moral anda dan akan membantu anda menemukan siapa diri anda sebenarnya\n",
              "1          1  ...                                                                                                            ini adalah salah satu yang harus saya miliki buku\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Fc1JABV6pX",
        "colab_type": "text"
      },
      "source": [
        "### Text to Sequence Conversion\n",
        "In Seq2Seq model we convert both the input and the output sentences into integer sequences of fixed length.\n",
        "\n",
        "Visualising the length of the sentences & capturing the lengths of all the sentences in two separate lists for English and Indonesian, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvI5jQEVTOJq",
        "colab_type": "code",
        "outputId": "1af2484c-47e4-40a5-8a1c-712fc92efc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "eng_l = []\n",
        "ind_l = []\n",
        "\n",
        "for i in data['raw_text']:\n",
        "  eng_l.append(len(i.split()))\n",
        "\n",
        "for i in data['review_text']:\n",
        "  ind_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng': eng_l, 'ind': ind_l})\n",
        "\n",
        "length_df.hist(bins=60)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJAkVQwHSVLFcJAkVQwHSVLFcJAkVf4/k70ty/2qFRcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUu7fSrtTVbO",
        "colab_type": "code",
        "outputId": "3f83ca76-a7e2-4617-9430-c7f9b108192d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('max_eng: ', max(eng_l), 'max_ind: ', max(ind_l))\n",
        "print('median_eng: ', np.median(eng_l), 'median_ind: ', np.median(ind_l))\n",
        "print('99percentile_eng: ', np.percentile(eng_l, q=99),\n",
        "      '99percentile_ind: ', np.percentile(ind_l, q=99))\n",
        "print('90percentile_eng: ', np.percentile(eng_l, q=90),\n",
        "      '90percentile_ind: ', np.percentile(ind_l, q=90))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_eng:  218 max_ind:  215\n",
            "median_eng:  14.0 median_ind:  12.0\n",
            "99percentile_eng:  54.0 99percentile_ind:  48.0\n",
            "90percentile_eng:  29.0 90percentile_ind:  26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tFhQkk9HQ0X",
        "colab_type": "text"
      },
      "source": [
        "the maximum length of the Indonesian sentences is 215 and that of the English phrases is 218.\n",
        "\n",
        "But 90% of data has sentence length of under 30, to make out matrix less sparse we will use length 30 cause 90% of data can be represented by sentence of length 30.\n",
        "\n",
        "Let's cap our Dataset to upto maximum 30 words sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPn47Ed0DlEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data['raw_text'].map(lambda x: len(x.split()))<=30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0OiLRDc3nj",
        "colab_type": "text"
      },
      "source": [
        "Vectorize our text data by using Keras’s **Tokenizer()** class. It will turn our sentences into sequences of integers. We can then pad those sequences with zeros to make all the sequences of the same length.\n",
        "\n",
        "Note that we will prepare tokenizers for both the Indonesian and English sentences:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpJ-_Ctvd1xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Afcty5YgfS",
        "colab_type": "code",
        "outputId": "b0e0c0c6-a6d8-4657-aeda-b6b1faab02e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare English tokenizer\n",
        "eng_tokenizer = tokenization(np.array(data['raw_text']))\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = 30\n",
        "\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 25362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orToK4-XeZEF",
        "colab_type": "code",
        "outputId": "ca664208-8924-49c6-b392-2d1a78da7f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare Indonesian tokenizer\n",
        "ind_tokenizer = tokenization(np.array(data['review_text']))\n",
        "ind_vocab_size = len(ind_tokenizer.word_index) + 1\n",
        "ind_length = 30\n",
        "\n",
        "print('Indonesian Vocabulary Size: %d' % ind_vocab_size)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indonesian Vocabulary Size: 19003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdUDFfZPhyI2",
        "colab_type": "text"
      },
      "source": [
        "Prepare the sequences & sequence padding to a maximum sentence length as mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKaegvhXegM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  # integet encode squences\n",
        "  seq = tokenizer.texts_to_sequences(lines)\n",
        "  # pad sequences with value 0\n",
        "  seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfyvwMjIh5m8",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C09pKL66hre_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.15, random_state=2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beqt4Boxh8j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preparing training data\n",
        "X_train = encode_sequences(ind_tokenizer, ind_length, np.array(train['review_text']))\n",
        "y_train = encode_sequences(eng_tokenizer, eng_length, np.array(train['raw_text']))\n",
        "\n",
        "# preparing training data\n",
        "X_test = encode_sequences(ind_tokenizer, ind_length, np.array(test['review_text']))\n",
        "y_test = encode_sequences(eng_tokenizer, eng_length, np.array(test['raw_text']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XCeQdcTjbFM",
        "colab_type": "text"
      },
      "source": [
        "Defining our Seq2Seq model architecture:\n",
        "\n",
        "* For the encoder, we will use an embedding layer and an LSTM layer.\n",
        "* For the decoder, we will use another LSTM layer followed by a dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpU1nv33jDxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=in_vocab, output_dim=units, input_length=in_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(units=units))\n",
        "  model.add(RepeatVector(out_timesteps))\n",
        "  model.add(LSTM(units=units, return_sequences=True))\n",
        "  model.add(Dense(out_vocab, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnix6JmhlJ8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model compilation\n",
        "model = define_model(ind_vocab_size, eng_vocab_size, ind_length, eng_length, 512);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7STs1I_NlKjf",
        "colab_type": "text"
      },
      "source": [
        "Using the RMSprop optimizer in this model as it’s usually a good choice when working with recurrent neural networks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD9ZgUGYlLsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms = optimizers.RMSprop(lr=0.001);\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylEMLkyxmHy2",
        "colab_type": "text"
      },
      "source": [
        "Using **‘sparse_categorical_crossentropy‘** as the loss function because the function allows to use the target sequence as is, instead of the one-hot encoded format. **One-hot encoding the target sequences using such a huge vocabulary might consume system’s entire memory.**\n",
        "\n",
        "**Training it for 30 epochs and with a batch size of 512 with a validation split of 15%.**\n",
        "\n",
        "Using the **ModelCheckpoint()** function to save the model with the lowest validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BdbudGal3oG",
        "colab_type": "code",
        "outputId": "d750dea7-f21a-4d72-b377-73856670b64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filename = 'model.h1.01_oct_2019'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(X_train, y_train.reshape(y_train.shape[0], y_train.shape[1], 1), epochs=30,\n",
        "                    batch_size=390, validation_split=0.15, callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 35449 samples, validate on 6256 samples\n",
            "Epoch 1/30\n",
            "35449/35449 [==============================] - 79s 2ms/step - loss: 3.9519 - val_loss: 3.6475\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.64755, saving model to model.h1.01_oct_2019\n",
            "Epoch 2/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.4736 - val_loss: 3.4815\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.64755 to 3.48154, saving model to model.h1.01_oct_2019\n",
            "Epoch 3/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.3293 - val_loss: 3.4377\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.48154 to 3.43774, saving model to model.h1.01_oct_2019\n",
            "Epoch 4/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.2571 - val_loss: 3.2286\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.43774 to 3.22861, saving model to model.h1.01_oct_2019\n",
            "Epoch 5/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.2083 - val_loss: 3.3111\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 3.22861\n",
            "Epoch 6/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.1616 - val_loss: 3.1397\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.22861 to 3.13975, saving model to model.h1.01_oct_2019\n",
            "Epoch 7/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.1049 - val_loss: 3.0977\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.13975 to 3.09768, saving model to model.h1.01_oct_2019\n",
            "Epoch 8/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 3.0476 - val_loss: 3.0670\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.09768 to 3.06699, saving model to model.h1.01_oct_2019\n",
            "Epoch 9/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.9878 - val_loss: 3.0293\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.06699 to 3.02934, saving model to model.h1.01_oct_2019\n",
            "Epoch 10/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.9307 - val_loss: 3.0030\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.02934 to 3.00296, saving model to model.h1.01_oct_2019\n",
            "Epoch 11/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.8735 - val_loss: 2.9577\n",
            "\n",
            "Epoch 00011: val_loss improved from 3.00296 to 2.95771, saving model to model.h1.01_oct_2019\n",
            "Epoch 12/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.8109 - val_loss: 2.9096\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.95771 to 2.90962, saving model to model.h1.01_oct_2019\n",
            "Epoch 13/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.7455 - val_loss: 2.8822\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.90962 to 2.88225, saving model to model.h1.01_oct_2019\n",
            "Epoch 14/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.6820 - val_loss: 2.8532\n",
            "\n",
            "Epoch 00014: val_loss improved from 2.88225 to 2.85321, saving model to model.h1.01_oct_2019\n",
            "Epoch 15/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.6201 - val_loss: 2.8281\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.85321 to 2.82811, saving model to model.h1.01_oct_2019\n",
            "Epoch 16/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.5585 - val_loss: 2.7840\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.82811 to 2.78401, saving model to model.h1.01_oct_2019\n",
            "Epoch 17/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.4983 - val_loss: 2.7796\n",
            "\n",
            "Epoch 00017: val_loss improved from 2.78401 to 2.77960, saving model to model.h1.01_oct_2019\n",
            "Epoch 18/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.4383 - val_loss: 2.7832\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.77960\n",
            "Epoch 19/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.3813 - val_loss: 2.7329\n",
            "\n",
            "Epoch 00019: val_loss improved from 2.77960 to 2.73291, saving model to model.h1.01_oct_2019\n",
            "Epoch 20/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.3234 - val_loss: 2.7130\n",
            "\n",
            "Epoch 00020: val_loss improved from 2.73291 to 2.71299, saving model to model.h1.01_oct_2019\n",
            "Epoch 21/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.2667 - val_loss: 2.6823\n",
            "\n",
            "Epoch 00021: val_loss improved from 2.71299 to 2.68232, saving model to model.h1.01_oct_2019\n",
            "Epoch 22/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.2109 - val_loss: 2.6661\n",
            "\n",
            "Epoch 00022: val_loss improved from 2.68232 to 2.66608, saving model to model.h1.01_oct_2019\n",
            "Epoch 23/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.1567 - val_loss: 2.6579\n",
            "\n",
            "Epoch 00023: val_loss improved from 2.66608 to 2.65785, saving model to model.h1.01_oct_2019\n",
            "Epoch 24/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.1038 - val_loss: 2.6786\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 2.65785\n",
            "Epoch 25/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.0537 - val_loss: 2.6211\n",
            "\n",
            "Epoch 00025: val_loss improved from 2.65785 to 2.62106, saving model to model.h1.01_oct_2019\n",
            "Epoch 26/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 2.0031 - val_loss: 2.6501\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 2.62106\n",
            "Epoch 27/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 1.9549 - val_loss: 2.6137\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.62106 to 2.61366, saving model to model.h1.01_oct_2019\n",
            "Epoch 28/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 1.9064 - val_loss: 2.6384\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 2.61366\n",
            "Epoch 29/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 1.8602 - val_loss: 2.6100\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.61366 to 2.60999, saving model to model.h1.01_oct_2019\n",
            "Epoch 30/30\n",
            "35449/35449 [==============================] - 77s 2ms/step - loss: 1.8133 - val_loss: 2.6255\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 2.60999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLkm10VOosWk",
        "colab_type": "text"
      },
      "source": [
        " Comparing the training loss and the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zQ_eCveolI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "711cf7ca-7e6e-4ea0-e906-369f495ee52e"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw3iqaGirW9E",
        "colab_type": "text"
      },
      "source": [
        "load the saved model and make predictions on the unseen data – testX."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQw3_F-trAya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model.h1.01_oct_2019')\n",
        "preds = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykDrHQwdsPS9",
        "colab_type": "text"
      },
      "source": [
        "These predictions are sequences of integers. We need to convert these integers to their corresponding words. Let’s define a function to do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7yYc5OesMVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words(n, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == n:\n",
        "      return word\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xRbt7kIvd1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = []\n",
        "ct = 0\n",
        "for i in preds:\n",
        "  ct += 1\n",
        "  print(ct)\n",
        "  temp = []\n",
        "  for j in range(len(i)):\n",
        "    t = get_words(i[j], eng_tokenizer)\n",
        "    if j > 0:\n",
        "      if (t == get_words(i[j-1], eng_tokenizer)) or (t==None):\n",
        "        temp.append('')\n",
        "      else:\n",
        "        temp.append(t)\n",
        "    else:\n",
        "      if (t==None):\n",
        "        temp.append('')\n",
        "      else:\n",
        "        temp.append(t)\n",
        "  preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMyGR4qJvvaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : np.array(test['raw_text']), 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-mgRatPY_0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c3a29058-3128-47e3-b1a5-2533cd319452"
      },
      "source": [
        "# print 15 rows rando/mly\n",
        "pred_df.sample(5)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3070</th>\n",
              "      <td>highly recommended</td>\n",
              "      <td>highly recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3427</th>\n",
              "      <td>in the hands of a powerful spirit a weakness can be transformed into a strength</td>\n",
              "      <td>the setting of the story is  can  to without</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2917</th>\n",
              "      <td>many people dont wish to understand that this movie is not about jesus being tortured but what he went through in his final moments on earth</td>\n",
              "      <td>what people to    the film    but   christ  the  jesus  the hours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6324</th>\n",
              "      <td>simple to use and fantastic</td>\n",
              "      <td>easy to easy and to and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>each character had so much to offer to the story</td>\n",
              "      <td>the author is to    the</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                             actual                                                                  predicted\n",
              "3070                                                                                                                             highly recommended                             highly recommended                            \n",
              "3427                                                                in the hands of a powerful spirit a weakness can be transformed into a strength            the setting of the story is  can  to without                   \n",
              "2917   many people dont wish to understand that this movie is not about jesus being tortured but what he went through in his final moments on earth  what people to    the film    but   christ  the  jesus  the hours        \n",
              "6324                                                                                                                    simple to use and fantastic                            easy to easy and to and                        \n",
              "3271                                                                                               each character had so much to offer to the story                              the author is to    the                      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LgNhWsgaM84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c1e02d9f-46e0-4741-c24a-dbad100e86ef"
      },
      "source": [
        "# print 15 rows rando/mly\n",
        "pred_df.sample(5)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>i got these nylons for a party in winter</td>\n",
              "      <td>i love this for     the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>works great</td>\n",
              "      <td>works great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1282</th>\n",
              "      <td>very sturdy</td>\n",
              "      <td>very sturdy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2735</th>\n",
              "      <td>the story is told by greer garason with  a great air of dignanty</td>\n",
              "      <td>the story is  by     the  a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4283</th>\n",
              "      <td>i also buy these to refill my larger unit since it is cheaper ordering it this way than individual brushes and rods</td>\n",
              "      <td>i also bought this for    i    a the with     and</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                     actual                                                    predicted\n",
              "1971                                                                               i got these nylons for a party in winter                 i love this for     the                     \n",
              "3764                                                                                                            works great                      works great                            \n",
              "1282                                                                                                            very sturdy                      very sturdy                            \n",
              "2735                                                       the story is told by greer garason with  a great air of dignanty                the story is  by     the  a                  \n",
              "4283    i also buy these to refill my larger unit since it is cheaper ordering it this way than individual brushes and rods  i also bought this for    i    a the with     and          "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKQq1HPdUK5",
        "colab_type": "text"
      },
      "source": [
        "Model seems to do great on short sentences whereas it struggle to perform good on long sentences.\n",
        "\n",
        "I might start performing good if we had larger training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXtjXsBudzk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c5330083-deb1-4b45-e805-2473802c7bc6"
      },
      "source": [
        "pred_df.sample(5)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>this pressure cooker is easy to use and maintains the quality of the end product better than convential cooking</td>\n",
              "      <td>this  is  easy and  to   the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850</th>\n",
              "      <td>there seems to be little common ground which is a shame as the movie should be judged solely on its merits</td>\n",
              "      <td>it is have a  of  but   that should to  of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6359</th>\n",
              "      <td>ive had two of these machines</td>\n",
              "      <td>i have this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3136</th>\n",
              "      <td>i found myself holding my breath for long durations of the novel anxiously awaiting what happens next</td>\n",
              "      <td>i was it at in a     for book   to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2734</th>\n",
              "      <td>the headset has yet to drop bluetooth connection on its own which is a first for all the headsets i8217ve owned and is kind of impressive</td>\n",
              "      <td>the bluetooth has have  a the       i  and   the as</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                          actual                                                      predicted\n",
              "4276                            this pressure cooker is easy to use and maintains the quality of the end product better than convential cooking                 this  is  easy and  to   the                   \n",
              "1850                                  there seems to be little common ground which is a shame as the movie should be judged solely on its merits      it is have a  of  but   that should to  of               \n",
              "6359                                                                                                               ive had two of these machines                         i have this                           \n",
              "3136                                       i found myself holding my breath for long durations of the novel anxiously awaiting what happens next              i was it at in a     for book   to               \n",
              "2734   the headset has yet to drop bluetooth connection on its own which is a first for all the headsets i8217ve owned and is kind of impressive  the bluetooth has have  a the       i  and   the as          "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    }
  ]
}